
model_config:
  qlarifais:
    # loss based on embedding output
    losses:
      #- type: cross_entropy # target dim needs to be adjusted
      #- type: binary cross-entropy loss # each question has multiple answers (MGFAN with ref.)
      - type: refiner_contrastive_loss
    classifier:
      type: simple
      output_type: embeddings # i.e. numberbatch embedding
      params:
        top_k: 3
        # input dim is the output of the fusion module
        in_dim: ${model_config.qlarifais.fusion.params.h_dim}
        out_dim: 300 # numberbatch output size
        norm: weight # [weight, batch, layer, none]
        act: ReLU # activation function
        h_dim: 300 # mean of input and output w.r.t. mlp
        num_non_linear_layers: 2 # activation functions
        # todo: optimization parameters:
        dropout: 0.1 # avoid overfitting, or keep all information?
