

includes:
    # include running experiment configs (defaults for all)
  - configs/experiments/defaults.yaml
    # define image encoder or keep resnet50 as default
  - configs/experiments/image_encoder/grids.yaml
  # default fusion is concat
  - configs/experiments/fusion/hadamard.yaml
    # default classifier is mlp


# overwrite included if necessary:


env:
  save_dir: ${env.part_save_dir}/logistic


model_config:
  qlarifais:


    classifier:
      type: sigmoid # [logit, sigmoid]
      params:
        in_dim: ${model_config.qlarifais.fusion.params.out_dim}
        out_dim: 2250
        # pythia
        img_hidden_dim: ${model_config.qlarifais.img_dim}
        text_hidden_dim: ${model_config.qlarifais.ques_dim}

      prior: false # initalize weight matrix for each answer vocabulary object
      # path to prior images per answer in answer vocabulary
      cache_dir: ${env.cache_dir}
      # path to dataset for answer vocabulary and building processors
      data_dir: ${dataset_config.${datasets}.data_dir}
      # path to answer vocabulary file
      processors: ${dataset_config.${datasets}.processors}




