
includes:
    # include running experiment configs (defaults for all)
  - configs/experiments/defaults.yaml
    # define image encoder or keep resnet50 as default
  - configs/experiments/image_encoder/grids.yaml
    # importing graph module
  - configs/experiments/graph/krisp.yaml
    # default fusion is simple concat
  - configs/experiments/fusion/multiply.yaml
    # default classifier is mlp
  - configs/experiments/classifier/logistic.yaml
# overwrite included if necessary:

env:
  save_dir: ${env.part_save_dir}/graph_guided


model_config:
  qlarifais:
    attention:
      use: true
      type: graph_guided
      params:
        modal_combine: # combining img and text
          type: non_linear_element_multiply # [-multiply, -concat]
          params:
            dropout: 0 # avoid overfitting
            hidden_dim: ${model_config.qlarifais.attention_hidden_dim} # or set to 2048?
        transform:
          type: linear
          params:
            out_dim: 1 # attention per feature
        normalization: softmax




