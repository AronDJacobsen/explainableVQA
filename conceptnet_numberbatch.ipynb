{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the embeddings from here:\n",
    "\n",
    "https://github.com/commonsense/conceptnet-numberbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'numberbatch-en-19.08.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c63da41e31e4620b42f00a4d0f8c6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=516782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "temp = {}\n",
    "\n",
    "with gzip.open(filename, 'rb') as f:\n",
    "    info = f.readlines(1)\n",
    "    lines, dim = (int(x) for x in info[0].decode('utf-8').strip(\"\\n\").split(\" \"))\n",
    "    \n",
    "    for line in tqdm(f, total=lines):\n",
    "        l = line.decode('utf-8')\n",
    "        l_split = l.strip(\"\\n\").split(\" \")\n",
    "\n",
    "        word = l_split[0]\n",
    "        arr = np.fromstring((\" \").join(l_split[1:]), dtype=float, sep=\" \")\n",
    "        temp[word] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How are you doing?\"\n",
    "question_tokens = word_tokenize(\"How are you doing?\".lower())\n",
    "\n",
    "\n",
    "q_embedding = []\n",
    "for token in question_tokens:\n",
    "    try:\n",
    "        arr = temp[token]\n",
    "        q_embedding.append(arr)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "q_embedding = np.mean(q_embedding, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12655 , -0.13745 , -0.023925,  0.0385  ,  0.0221  ,  0.047425,\n",
       "        0.0451  , -0.052325,  0.161825, -0.045125, -0.03885 ,  0.0938  ,\n",
       "       -0.10435 , -0.095425,  0.051825,  0.0467  ,  0.043775,  0.0657  ,\n",
       "        0.0379  ,  0.024125,  0.034975, -0.054825,  0.072425,  0.046075,\n",
       "        0.0133  , -0.09285 ,  0.01895 ,  0.028675,  0.0316  ,  0.041225,\n",
       "       -0.054475,  0.041075,  0.054975,  0.048875, -0.013325,  0.0299  ,\n",
       "        0.059675,  0.01    , -0.0577  , -0.027675, -0.056525, -0.03845 ,\n",
       "        0.03665 ,  0.069875, -0.096825, -0.033325,  0.05985 , -0.038825,\n",
       "       -0.03295 , -0.085525,  0.004   ,  0.023975,  0.018   ,  0.03855 ,\n",
       "       -0.00325 ,  0.036125,  0.007125, -0.058525,  0.02935 , -0.0679  ,\n",
       "       -0.15785 ,  0.004575, -0.1011  ,  0.00185 ,  0.0084  ,  0.028125,\n",
       "        0.03065 ,  0.077425,  0.039625,  0.00045 ,  0.00595 , -0.03365 ,\n",
       "        0.0612  ,  0.000875, -0.047825,  0.03055 , -0.0403  , -0.0291  ,\n",
       "        0.026725, -0.03335 , -0.0338  ,  0.01825 , -0.031   ,  0.023325,\n",
       "        0.023975, -0.024525,  0.02725 , -0.015625, -0.006825, -0.0346  ,\n",
       "        0.00755 , -0.019225,  0.0242  ,  0.005425, -0.004525,  0.056225,\n",
       "       -0.02595 ,  0.040925, -0.0376  , -0.033325, -0.0418  , -0.003025,\n",
       "        0.034875,  0.05275 , -0.018575,  0.048575,  0.032625, -0.013825,\n",
       "       -0.02505 , -0.01395 , -0.01025 ,  0.03775 ,  0.00985 ,  0.038175,\n",
       "       -0.013225, -0.0211  ,  0.033125,  0.005225,  0.0459  , -0.030025,\n",
       "       -0.013175,  0.019725,  0.024125,  0.000575,  0.01885 , -0.0039  ,\n",
       "       -0.021675,  0.009475, -0.006025,  0.008375, -0.0508  , -0.038475,\n",
       "        0.0368  ,  0.027325,  0.00185 , -0.024475,  0.004525,  0.017825,\n",
       "       -0.01575 , -0.01935 ,  0.002325, -0.017375, -0.000475,  0.02905 ,\n",
       "        0.001175,  0.044975,  0.01985 , -0.014125,  0.034225,  0.008   ,\n",
       "       -0.001175, -0.05505 ,  0.0249  , -0.0174  , -0.018725, -0.036725,\n",
       "       -0.0236  ,  0.021525,  0.034975,  0.064825,  0.033175, -0.020675,\n",
       "       -0.002725,  0.044   , -0.0337  ,  0.002575,  0.0046  ,  0.0029  ,\n",
       "       -0.033125,  0.004125,  0.028125, -0.041375,  0.00075 , -0.0237  ,\n",
       "        0.001225,  0.046275,  0.04115 ,  0.016625,  0.036175, -0.017375,\n",
       "        0.017425,  0.017725,  0.024325, -0.010375,  0.00355 , -0.00645 ,\n",
       "        0.034175, -0.0142  ,  0.016825,  0.015725, -0.0148  , -0.060625,\n",
       "       -0.0168  ,  0.033325, -0.02255 , -0.02555 ,  0.063575,  0.02    ,\n",
       "       -0.03515 ,  0.052   , -0.00985 , -0.01155 , -0.013225,  0.0145  ,\n",
       "        0.059275, -0.0084  , -0.030525,  0.070725,  0.003725,  0.003275,\n",
       "        0.017275,  0.010525,  0.01035 , -0.039875,  0.037575, -0.0423  ,\n",
       "       -0.0569  ,  0.0701  ,  0.00135 , -0.0042  ,  0.0063  ,  0.0111  ,\n",
       "        0.0576  ,  0.065825,  0.008875,  0.04855 , -0.048625,  0.01205 ,\n",
       "        0.01265 , -0.014925, -0.02035 , -0.00975 , -0.006525, -0.051275,\n",
       "       -0.014225,  0.03965 , -0.039275,  0.02085 ,  0.0019  , -0.00975 ,\n",
       "       -0.009525, -0.025775,  0.08395 ,  0.03195 , -0.00165 ,  0.015975,\n",
       "       -0.03615 ,  0.017   ,  0.006025,  0.015025, -0.04735 ,  0.00285 ,\n",
       "       -0.00375 ,  0.02    ,  0.034925,  0.029875, -0.045025, -0.006825,\n",
       "        0.006675, -0.036275,  0.019625, -0.008975,  0.025125, -0.033025,\n",
       "       -0.0971  ,  0.061175,  0.01    , -0.01495 ,  0.06695 , -0.006925,\n",
       "       -0.00355 ,  0.0404  , -0.007   ,  0.028225, -0.01765 ,  0.01465 ,\n",
       "       -0.0008  , -0.0231  , -0.01085 , -0.04245 , -0.05345 ,  0.005975,\n",
       "        0.034825,  0.03605 , -0.048575, -0.0048  , -0.072925, -0.078425,\n",
       "       -0.04525 ,  0.009625, -0.036975, -0.006225, -0.021825,  0.01685 ,\n",
       "       -0.0064  , -0.01425 ,  0.0388  , -0.03605 ,  0.023175,  0.03695 ])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
